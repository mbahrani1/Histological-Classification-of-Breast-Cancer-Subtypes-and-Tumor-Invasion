# -*- coding: utf-8 -*-
"""project_obj_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1exfEpKocSAGgB4uxP_R8llBVWXNcqeJi

## Project Overview
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
import cv2
import csv
import time
import numpy as np
import pandas as pd
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.model_selection import train_test_split
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.optim import Adam
from sklearn.metrics import confusion_matrix
import seaborn as sns
# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix
from tqdm.notebook import tqdm
import torchvision.transforms.functional as TF

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

class config:
    batchsize = 8
    num_epochs = 50
    learning_rate = 1e-4
    num_classes = 4

pd.set_option('future.no_silent_downcasting', True)

"""## Data Loading, Labels, and Splits"""

dataset_path  = "./drive/MyDrive/umich_courses/1_fall_2025/1_term_project/data/BACH/ICIAR2018_BACH_Challenge/Photos"
csv_path      = "./drive/MyDrive/umich_courses/1_fall_2025/1_term_project/data/BACH/ICIAR2018_BACH_Challenge/Photos/microscopy_ground_truth.csv"

df = pd.read_csv(csv_path)
image_paths, labels = [], []

for class_name in ["Benign", "InSitu", "Invasive", "Normal"]:
    class_path = os.path.join(dataset_path, class_name)
    for img_name in os.listdir(class_path):
        if img_name.endswith(".tif"):
            image_paths.append(os.path.join(class_path, img_name))
            labels.append(class_name)


image_df = pd.DataFrame({"image_path": image_paths, "label": labels})

image_df["label"] = image_df["label"].replace({"Normal": 0, "Benign": 1, "InSitu": 2, "Invasive": 3}).astype("int64")
image_df = image_df.sample(frac=1, random_state=42).reset_index(drop=True)
image_df.to_csv("bach_training_data.csv", index=False)

dataset = pd.read_csv("bach_training_data.csv")
dataset.head()

"""## Preprocessing, Augmentation, and DataLoaders

This section defines image preprocessing steps such as resizing, normalization, and optional augmentation. The processed data is wrapped into PyTorch `Dataset` and `DataLoader` objects so that images can be efficiently batched, shuffled, and fed into the model during training and evaluation.

"""

class BACHDataset(Dataset):
    def __init__(self, data, transform=None):
        self.data = data
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx]["image_path"]
        label = torch.tensor(self.data.iloc[idx]["label"], dtype=torch.long)
        image = Image.open(img_path).convert("RGB")
        image = cv2.resize(np.array(image), (224, 224), interpolation=cv2.INTER_AREA)
        image = Image.fromarray(image)
        if self.transform:
            image = self.transform(image)
        else:
            image = transforms.ToTensor()(image)

        return image, label

class MinMaxScalerTransform:
    def __call__(self, img):
        img_array = np.array(img).astype(np.float32) / 255.0
        return torch.tensor(img_array).permute(2, 0, 1)

data_transforms = transforms.Compose([
    MinMaxScalerTransform(),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)
])

train, temp = train_test_split(dataset, test_size=0.2, stratify=dataset["label"], random_state=42)
val, test = train_test_split(temp, test_size=0.25, stratify=temp["label"], random_state=42)

train_dataset = BACHDataset(train, transform=data_transforms)
val_dataset = BACHDataset(val, transform=None)
test_dataset = BACHDataset(test, transform=None)

train_dataloader = DataLoader(train_dataset, batch_size=config.batchsize, shuffle=False)
val_dataloader = DataLoader(val_dataset, batch_size=config.batchsize, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=config.batchsize, shuffle=True)

def show_samples(dataloader, title, num_samples=5):
    print(f"\n{title} - Total Batches: {len(dataloader)} | Total Samples: {len(dataloader.dataset)}")


    batch = next(iter(dataloader))

    if isinstance(batch, tuple) and len(batch) == 2:
        images, labels = batch
    elif isinstance(batch, list) and len(batch) == 2:
        images, labels = batch[0], batch[1]
    else:
        raise ValueError(f"Unexpected batch format from DataLoader: {type(batch)}, content: {batch}")


    if isinstance(images, list):
        images = torch.stack(images)


    if images.ndim == 3:
        images = images.unsqueeze(0)

    num_samples = min(num_samples, images.shape[0])


    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))
    if num_samples == 1:
        axes = [axes]
    for i in range(num_samples):
        img_tensor = images[i]
        img = TF.to_pil_image(img_tensor.cpu())
        label = labels[i].item() if isinstance(labels[i], torch.Tensor) else labels[i]
        img_shape = tuple(img_tensor.shape)

        axes[i].imshow(img)
        axes[i].set_title(f"Label: {label}\nShape: {img_shape}")
        axes[i].axis("off")



    plt.show()

show_samples(train_dataloader, "Train Samples")
show_samples(val_dataloader, "Validation Samples")
show_samples(test_dataloader, "Test Samples")

"""## Model Architecture & Training Configuration

Here we define the neural network architecture based on a ResNet backbone with a custom classification head adapted to the four BACH classes. We also specify the loss function, optimizer, learning rate, and other hyperparameters that control how the model learns from the data.

"""

model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)


for param in model.layer1.parameters() :
        param.requires_grad = False
for param in model.layer2.parameters() :
        param.requires_grad = False
for param in model.layer3.parameters() :
        param.requires_grad = False
for param in model.layer4.parameters() :
        param.requires_grad = True
num_features = model.fc.in_features
num_classes = 4


model.fc = nn.Sequential(
    nn.Linear(num_features, 1024),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(1024, 512),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(256, num_classes)
)


model = model.to(device)


criterion = nn.CrossEntropyLoss()


class_weights = torch.tensor([1.0, 1.5, 1.0, 1.0], dtype=torch.float32).to(device)


criterion_w = nn.CrossEntropyLoss(weight=class_weights)


optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)


scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', patience=3, factor=0.5
)

import torch
import torch.nn.functional as F

def convert_to_one_hot(label, num_classes):


    return F.one_hot(torch.tensor(label), num_classes).float()  # Shape: (num_classes,)

def compute_multiclass_metrics(preds_list, labels_list, num_classes):

    # Initialize per-class metric accumulators
    TP_per_class = torch.zeros(num_classes)
    TN_per_class = torch.zeros(num_classes)
    FP_per_class = torch.zeros(num_classes)
    FN_per_class = torch.zeros(num_classes)

    correct = 0
    total = len(labels_list)

    for preds, label in zip(preds_list, labels_list):

        label_one_hot = convert_to_one_hot(label, num_classes)


        pred_class = torch.argmax(preds)
        pred_one_hot = convert_to_one_hot(preds, num_classes)


        if preds == label:
            correct += 1


        for class_idx in range(num_classes):

            TP_per_class[class_idx] += int((pred_one_hot[class_idx] == 1) and (label_one_hot[class_idx] == 1))

            TN_per_class[class_idx] += int((pred_one_hot[class_idx] == 0) and (label_one_hot[class_idx] == 0))

            FP_per_class[class_idx] += int((pred_one_hot[class_idx] == 1) and (label_one_hot[class_idx] == 0))

            FN_per_class[class_idx] += int((pred_one_hot[class_idx] == 0) and (label_one_hot[class_idx] == 1))


    precision_per_class = TP_per_class / (TP_per_class + FP_per_class).clamp(min=1e-10)

    recall_per_class = TP_per_class / (TP_per_class + FN_per_class).clamp(min=1e-10)

    specificity_per_class = TN_per_class / (TN_per_class + FP_per_class).clamp(min=1e-10)

    f1_score_per_class = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class).clamp(min=1e-10)



    macro_precision = precision_per_class.mean().item()
    macro_recall = recall_per_class.mean().item()
    macro_specificity = specificity_per_class.mean().item()
    macro_f1_score = f1_score_per_class.mean().item()


    accuracy = correct / total

    return {
        "accuracy": accuracy,
        "precision_per_class": precision_per_class.tolist(),
        "macro_precision": macro_precision,
        "recall_per_class": recall_per_class.tolist(),
        "macro_recall": macro_recall,
        "specificity_per_class": specificity_per_class.tolist(),
        "macro_specificity": macro_specificity,
        "f1_score_per_class": f1_score_per_class.tolist(),
        "macro_f1_score": macro_f1_score
    }

def plot_loss(train_losses, val_losses, num_epochs):
    """Plots training and validation loss curves."""
    plt.figure(figsize=(10, 5))
    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', marker='o', linestyle='-')
    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', marker='s', linestyle='--')
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training vs Validation Loss")
    plt.legend()
    plt.grid(True)
    plt.show()

"""## Model Training & Validation

This section implements the training and validation loops. Across multiple epochs, the model is updated using the training set while performance on the validation set is monitored using metrics such as loss, accuracy, and F1-score to detect underfitting or overfitting.

"""

def train_model(model, optimizer, criterion, train_dataloader, val_dataloader, num_epochs, device, num_classes, model_path, csv_name):

    log_fields = ["epoch", "time", "train_loss", "val_loss", "train_precision", "val_precision",
              "train_recall", "val_recall", "train_F1_Score", "val_F1_Score"]
    total_training_time = 0
    best_val_F1_Score = 0

    train_losses = []
    val_losses = []

    with open(csv_name, 'w', newline='', encoding='utf-8') as csvfile:
         writer = csv.DictWriter(csvfile, fieldnames=log_fields)
         writer.writeheader()

    for epoch in range(num_epochs):
        start_time = time.time()
        model.train()

        total_loss = 0
        correct = 0
        total = 0

        all_preds = []
        all_labels = []



        train_iterator = tqdm(train_dataloader, desc=f"Epoch {epoch + 1}")

        for images, labels in train_iterator:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            preds = F.softmax(outputs, dim=1)
            preds = torch.argmax(preds, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)


            all_preds.append(preds.detach().cpu())
            all_labels.append(labels.detach().cpu())

            train_iterator.set_postfix(loss=f"{loss:.4f}")

        epoch_time = time.time() - start_time
        total_training_time += epoch_time
        accuracy = correct / total


        all_preds = torch.cat(all_preds, dim=0)
        all_labels = torch.cat(all_labels, dim=0)


        metrics = compute_multiclass_metrics(all_preds, all_labels, num_classes)

        epoch_train_loss = total_loss / len(train_dataloader)
        train_losses.append(epoch_train_loss)


        # Print metrics for each class
        print(f"Epoch {epoch + 1} - Loss: {epoch_train_loss:.4f}, Accuracy: {accuracy:.4f}, Time: {epoch_time:.2f}s")
        print(f"Macro Precision: {metrics['macro_precision']:.4f}, Macro Recall: {metrics['macro_recall']:.4f}, Macro F1-score: {metrics['macro_f1_score']:.4f}")

        for class_idx in range(num_classes):
            print(f"Class {class_idx} - Precision: {metrics['precision_per_class'][class_idx]:.4f}, Recall: {metrics['recall_per_class'][class_idx]:.4f}, F1-score: {metrics['f1_score_per_class'][class_idx]:.4f}")

        all_val_preds,all_val_labels,val_accuracy, val_loss = valid_model(model,criterion, val_dataloader, device, epoch, num_classes)
        val_metrics = compute_multiclass_metrics(all_val_preds, all_val_labels, num_classes)
        val_losses.append(val_loss)
        print("Validation_Metrics")
        print(f"Epoch {epoch + 1} - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}")
        print(f"Macro Precision: {val_metrics['macro_precision']:.4f}, Macro Recall: {val_metrics['macro_recall']:.4f}, Macro F1-score: {val_metrics['macro_f1_score']:.4f}")

        for class_idx in range(num_classes):
            print(f"Class {class_idx} - Precision: {val_metrics['precision_per_class'][class_idx]:.4f}, Recall: {val_metrics['recall_per_class'][class_idx]:.4f}, F1-score: {val_metrics['f1_score_per_class'][class_idx]:.4f}")

            # Save best model based on Dice score
        if val_metrics['macro_f1_score'] > best_val_F1_Score:
            best_val_F1_Score = val_metrics['macro_f1_score']
            torch.save(model.state_dict(), model_path)
            print(f"Model saved at epoch {epoch+1} with F1_score: {best_val_F1_Score:.4f}")
            # Log training and validation metrics
        with open(csv_name, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=log_fields)
            writer.writerow({
                "epoch": epoch + 1,
                "time": round(epoch_time, 2),
                "train_loss": round(total_loss/len(train_dataloader), 4),
                "val_loss": round(val_loss, 4),
                "train_precision": round(metrics['macro_precision'], 4),
                "val_precision": round(val_metrics['macro_precision'], 4),
                "train_recall": round(metrics['macro_recall'], 4),
                "val_recall": round(val_metrics['macro_recall'], 4),
                "train_F1_Score": round(metrics['macro_f1_score'], 4),
                "val_F1_Score": round(val_metrics['macro_f1_score'], 4),

            })


    print(f"Training Complete in {total_training_time:.4f}s with {total_training_time/num_epochs:.4f}s per epoch with Best_F1_Score {best_val_F1_Score:.4f}.")
    print(f"Best Validation F1 Score: {best_val_F1_Score:.4f}")

    plot_loss(train_losses, val_losses, num_epochs)

def valid_model(model,criterion, dataloader, device, epoch, num_classes):

    all_val_preds = []
    all_val_labels = []
    val_loss = 0
    val_correct = 0
    val_total= 0
    model.eval()

    val_iterator = tqdm(dataloader, desc=f"Epoch {epoch + 1}")

    with torch.no_grad():
            for images,labels  in val_iterator:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)

                loss = criterion(outputs, labels)
                val_loss += loss.item()

                preds = F.softmax(outputs, dim=1)
                preds = torch.argmax(preds, dim=1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)


                all_val_preds.append(preds.detach().cpu())
                all_val_labels.append(labels.detach().cpu())

    val_iterator.set_postfix(loss=f"{loss:.4f}")
    val_accuracy = val_correct / val_total
    all_val_preds = torch.cat(all_val_preds, dim=0)
    all_val_labels = torch.cat(all_val_labels, dim=0)
    val_loss /= len(dataloader)
    scheduler.step(val_loss)

    return all_val_preds,all_val_labels,val_accuracy, val_loss

def inference_model(model, model_path, dataloader, device, num_classes):


    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device).eval()

    all_preds = []
    all_labels = []

    inference_iterator = tqdm(dataloader, desc="Running Inference")

    start_time = time.time()

    with torch.no_grad():
        for images, labels in inference_iterator:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)

            preds = F.softmax(outputs, dim=1)
            preds = torch.argmax(preds, dim=1)


            all_preds.append(preds.cpu())
            all_labels.append(labels.cpu())


    all_preds = torch.cat(all_preds, dim=0)
    all_labels = torch.cat(all_labels, dim=0)


    metrics = compute_multiclass_metrics(all_preds, all_labels, num_classes)

    # confusion matrix heatmap
    # Convert tensors to numpy arrays
    y_true = all_labels.numpy()
    y_pred = all_preds.numpy()

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Class names must match your label encoding:
    # "Normal": 0, "Benign": 1, "InSitu": 2, "Invasive": 3
    class_names = ["Normal", "Benign", "InSitu", "Invasive"]

    # Plot confusion matrix
    plot_confusion_matrix(
        cm,
        class_names=class_names,
        title="Confusion Matrix - Test Set",

        save_path="confusion_matrix_test.png"  # or None if you don't want to save
    )


    inference_time = time.time() - start_time
    print(f"\nInference Completed in {inference_time:.2f}s")

    print(f"\nMacro Precision: {metrics['macro_precision']:.4f}, Macro Recall: {metrics['macro_recall']:.4f}, Macro F1-score: {metrics['macro_f1_score']:.4f}")

    for class_idx in range(num_classes):
        print(f"Class {class_idx} - Precision: {metrics['precision_per_class'][class_idx]:.4f}, Recall: {metrics['recall_per_class'][class_idx]:.4f}, F1-score: {metrics['f1_score_per_class'][class_idx]:.4f}")

def plot_confusion_matrix(cm, class_names, title="Confusion Matrix", save_path=None):
    plt.figure(figsize=(6, 5))
    sns.heatmap(
        cm,
        annot=True,
        fmt="d",
        cmap="gray_r",
        xticklabels=class_names,
        yticklabels=class_names,
        linewidths=0.5,
        linecolor=None#'black'
    )
    plt.title(title)
    plt.ylabel("True Label")
    plt.xlabel("Predicted Label")
    plt.tight_layout()

    if save_path is not None:
        plt.savefig(save_path, bbox_inches='tight', dpi=300)
        print(f"Confusion matrix saved to: {save_path}")

    plt.show()

train_model(model, optimizer, criterion, train_dataloader, val_dataloader, config.num_epochs, device,config.num_classes, model_path="best_model1.pth", csv_name="training_results1.csv")

"""## Test Evaluation & Result Visualization

Here we evaluate the trained model on the held-out test set to estimate real-world performance. Metrics and visualizations such as confusion matrices and sample predictions are used to understand how well the model distinguishes between the different breast cancer subtypes.

"""

best_model_path = "./drive/MyDrive/umich_courses/1_fall_2025/1_term_project/code/best_model1.pth"
inference_model(model, best_model_path, test_dataloader, device, config.num_classes)

